# RAG ë””ë²„ê¹…/ë¦¬ë‹ˆì§€ ì¶”ì  ê¸°ëŠ¥ êµ¬í˜„ ê³„íš

## ë°°ê²½
Qdrant ê¸°ë°˜ Knowledge Base RAGê°€ íƒ‘ìž¬ë˜ì—ˆìœ¼ë‚˜, í”Œëž˜ë‹ ê³¼ì •ì—ì„œ ì–´ë–¤ ë¬¸ì„œì˜ ì–´ë–¤ ë¶€ë¶„ì´ ë°œì·Œë˜ì–´ ê¸°ì—¬í–ˆëŠ”ì§€ ì¶”ì í•˜ê¸° ì–´ë ¤ì›€.

## ëª©í‘œ
RAG ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ì˜ ì „ì²´ ë¦¬ë‹ˆì§€ ì¶”ì ì´ ê°€ëŠ¥í•œ ë””ë²„ê¹… ë„êµ¬ êµ¬í˜„

## êµ¬í˜„ ë²”ìœ„
1. **CLI ìŠ¤í¬ë¦½íŠ¸**: í„°ë¯¸ë„ì—ì„œ í”„ë¡¬í”„íŠ¸ ìž…ë ¥ â†’ ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
2. **API ì—”ë“œí¬ì¸íŠ¸**: `POST /rag/debug` HTTP ì—”ë“œí¬ì¸íŠ¸
3. **ì „ì²´ íŒŒì´í”„ë¼ì¸ ê°€ì‹œì„±**: ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°ì§€ â†’ ê²€ìƒ‰ â†’ ì ìˆ˜ ê³„ì‚° â†’ ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
4. **ìœ ë‹›í…ŒìŠ¤íŠ¸**: Mock ê¸°ë°˜ í…ŒìŠ¤íŠ¸ (í† í° ì†Œë¹„ 0)

---

## Phase 1: ë°ì´í„° êµ¬ì¡° ì¶”ê°€

### íŒŒì¼: `agent-server/agent_server/schemas/rag.py`

ìƒˆë¡œìš´ Pydantic ëª¨ë¸ ì¶”ê°€:

```python
class ChunkDebugInfo(BaseModel):
    """ì²­í¬ë³„ ìƒì„¸ ì ìˆ˜ ì •ë³´"""
    chunk_id: str
    content_preview: str  # ì²˜ìŒ 200ìž
    dense_score: float    # Dense vector ìœ ì‚¬ë„ (0-1)
    bm25_score: Optional[float]      # BM25 ì •ê·œí™” ì ìˆ˜
    bm25_raw_score: Optional[float]  # BM25 ì›ë³¸ ì ìˆ˜
    fused_score: float    # ìµœì¢… ìœµí•© ì ìˆ˜
    rank_dense: int       # Dense ìˆœìœ„
    rank_bm25: Optional[int]  # BM25 ìˆœìœ„
    rank_final: int       # ìµœì¢… ìˆœìœ„
    metadata: Dict[str, Any]  # source, section ë“±
    passed_threshold: bool    # threshold í†µê³¼ ì—¬ë¶€

class LibraryDetectionDebug(BaseModel):
    """ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°ì§€ ë‹¨ê³„ ë””ë²„ê·¸ ì •ë³´"""
    input_query: str
    imported_libraries: List[str]
    available_libraries: List[str]
    detected_libraries: List[str]
    detection_method: str

class SearchConfigDebug(BaseModel):
    """ê²€ìƒ‰ ì„¤ì • ì •ë³´"""
    top_k: int
    score_threshold: float
    use_hybrid_search: bool
    hybrid_alpha: float
    max_context_tokens: int

class DebugSearchRequest(BaseModel):
    """ë””ë²„ê·¸ ê²€ìƒ‰ ìš”ì²­"""
    query: str
    imported_libraries: List[str] = []
    top_k: Optional[int] = None
    include_full_content: bool = False
    simulate_plan_context: bool = True

class DebugSearchResponse(BaseModel):
    """ë””ë²„ê·¸ ê²€ìƒ‰ ì‘ë‹µ"""
    library_detection: LibraryDetectionDebug
    config: SearchConfigDebug
    chunks: List[ChunkDebugInfo]
    total_candidates: int
    total_passed_threshold: int
    dense_search_ms: float
    bm25_search_ms: Optional[float]
    total_search_ms: float
    formatted_context: str
    context_char_count: int
    estimated_context_tokens: int
```

---

## Phase 2: Retriever í™•ìž¥

### íŒŒì¼: `agent-server/agent_server/core/retriever.py`

`search_with_debug()` ë©”ì„œë“œ ì¶”ê°€:

```python
from dataclasses import dataclass
from typing import NamedTuple
import time

@dataclass
class ChunkScoreDetails:
    """ë‚´ë¶€ ë°ì´í„° êµ¬ì¡°: ì²­í¬ë³„ ì ìˆ˜ ìƒì„¸"""
    chunk_id: str
    content: str
    dense_score: float
    bm25_score: Optional[float]
    bm25_raw_score: Optional[float]
    fused_score: float
    rank_dense: int
    rank_bm25: Optional[int]
    rank_final: int
    metadata: Dict[str, Any]
    passed_threshold: bool

class DebugSearchResult(NamedTuple):
    """ë””ë²„ê·¸ ê²€ìƒ‰ ê²°ê³¼"""
    chunks: List[ChunkScoreDetails]
    dense_search_ms: float
    bm25_search_ms: Optional[float]
    total_search_ms: float
    total_candidates: int

class Retriever:
    # ... ê¸°ì¡´ ë©”ì„œë“œ ...

    async def search_with_debug(
        self,
        query: str,
        top_k: Optional[int] = None,
        filters: Optional[Dict[str, Any]] = None,
        score_threshold: Optional[float] = None
    ) -> DebugSearchResult:
        """
        ì „ì²´ ì ìˆ˜ ì •ë³´ë¥¼ í¬í•¨í•œ ë””ë²„ê·¸ ê²€ìƒ‰ ìˆ˜í–‰

        1. Dense search (with timing)
        2. BM25 scoring (if hybrid enabled)
        3. Score fusion (alpha * dense + (1-alpha) * bm25)
        4. Rankings for all scoring methods
        5. Return detailed ChunkScoreDetails
        """
        start_time = time.perf_counter()

        # Query embedding
        query_embedding = self._embedding_service.embed_query(query)

        # Dense search with timing
        dense_start = time.perf_counter()
        dense_results = self._client.search(
            collection_name=self._config.qdrant.collection_name,
            query_vector=query_embedding,
            limit=top_k * 3,  # ë””ë²„ê·¸ìš©ìœ¼ë¡œ ë” ë§Žì´ ê°€ì ¸ì˜´
            score_threshold=threshold * 0.3  # ë‚®ì€ thresholdë¡œ ë” ë§Žì€ ê²°ê³¼
        )
        dense_ms = (time.perf_counter() - dense_start) * 1000

        # Dense rankings ìƒì„±
        dense_rankings = {r.id: (i + 1, r.score) for i, r in enumerate(dense_results)}

        # BM25 scoring (if hybrid)
        bm25_ms = None
        normalized_bm25 = {}
        raw_bm25 = {}
        bm25_rankings = {}

        if self._should_use_hybrid():
            bm25_start = time.perf_counter()
            # ... BM25 ê³„ì‚° ë¡œì§ ...
            bm25_ms = (time.perf_counter() - bm25_start) * 1000

        # Fused scores ê³„ì‚°
        alpha = self._config.hybrid_alpha
        fused_scores = {}
        for r in dense_results:
            dense_score = r.score
            bm25_norm = normalized_bm25.get(r.id, 0.0)
            fused_scores[r.id] = alpha * dense_score + (1 - alpha) * bm25_norm

        # Final rankings
        sorted_ids = sorted(fused_scores.keys(), key=lambda x: fused_scores[x], reverse=True)
        final_rankings = {doc_id: (rank + 1) for rank, doc_id in enumerate(sorted_ids)}

        # Build detailed results
        chunks = []
        for doc_id in sorted_ids:
            result = id_to_result[doc_id]
            chunks.append(ChunkScoreDetails(
                chunk_id=str(doc_id),
                content=result.payload.get("content", ""),
                dense_score=round(dense_rankings[doc_id][1], 4),
                bm25_score=round(normalized_bm25.get(doc_id, 0.0), 4),
                bm25_raw_score=round(raw_bm25.get(doc_id, 0.0), 4),
                fused_score=round(fused_scores[doc_id], 4),
                rank_dense=dense_rankings[doc_id][0],
                rank_bm25=bm25_rankings.get(doc_id),
                rank_final=final_rankings[doc_id],
                metadata={k: v for k, v in result.payload.items() if k != "content"},
                passed_threshold=fused_scores[doc_id] >= threshold
            ))

        return DebugSearchResult(
            chunks=chunks,
            dense_search_ms=round(dense_ms, 2),
            bm25_search_ms=round(bm25_ms, 2) if bm25_ms else None,
            total_search_ms=round((time.perf_counter() - start_time) * 1000, 2),
            total_candidates=len(dense_results)
        )
```

---

## Phase 3: RAGManager í™•ìž¥

### íŒŒì¼: `agent-server/agent_server/core/rag_manager.py`

`debug_search()` ë©”ì„œë“œ ì¶”ê°€:

```python
async def debug_search(
    self,
    query: str,
    imported_libraries: List[str] = None,
    top_k: Optional[int] = None,
    include_full_content: bool = False,
    simulate_plan_context: bool = True
) -> Dict[str, Any]:
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¦¬ë‹ˆì§€ë¥¼ í¬í•¨í•œ ë””ë²„ê·¸ ê²€ìƒ‰

    ë°˜í™˜ ì •ë³´:
    - ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°ì§€ ê²°ê³¼
    - ì²­í¬ë³„ ì ìˆ˜ (dense, BM25, fused)
    - ìµœì¢… í¬ë§·ëœ ì»¨í…ìŠ¤íŠ¸
    """
    if not self._ready:
        return {"error": "RAG system not ready"}

    # 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°ì§€ (agent.pyì™€ ë™ì¼ ë¡œì§)
    from agent_server.knowledge.loader import get_knowledge_base, get_library_detector

    knowledge_base = get_knowledge_base()
    library_detector = get_library_detector()
    available = knowledge_base.list_available_libraries()
    detected_libraries = library_detector.detect(
        request=query,
        available_libraries=available,
        imported_libraries=imported_libraries or []
    )

    library_detection_info = {
        "input_query": query,
        "imported_libraries": imported_libraries or [],
        "available_libraries": available or [],
        "detected_libraries": detected_libraries,
        "detection_method": "deterministic"
    }

    # 2. ë””ë²„ê·¸ ê²€ìƒ‰ ìˆ˜í–‰
    debug_result = await self._retriever.search_with_debug(
        query=query,
        top_k=top_k or self._config.top_k
    )

    # 3. ì²­í¬ ë””ë²„ê·¸ ì •ë³´ êµ¬ì„±
    chunks_info = []
    for chunk in debug_result.chunks:
        chunks_info.append({
            "chunk_id": chunk.chunk_id,
            "content_preview": chunk.content[:200] + "..." if len(chunk.content) > 200 else chunk.content,
            "dense_score": chunk.dense_score,
            "bm25_score": chunk.bm25_score,
            "bm25_raw_score": chunk.bm25_raw_score,
            "fused_score": chunk.fused_score,
            "rank_dense": chunk.rank_dense,
            "rank_bm25": chunk.rank_bm25,
            "rank_final": chunk.rank_final,
            "metadata": chunk.metadata,
            "passed_threshold": chunk.passed_threshold
        })

    # 4. í¬ë§·ëœ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (get_context_for_queryì™€ ë™ì¼)
    formatted_context = ""
    if simulate_plan_context:
        passed_chunks = [c for c in debug_result.chunks if c.passed_threshold]
        # ... ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ… ...

    return {
        "library_detection": library_detection_info,
        "config": {...},
        "chunks": chunks_info,
        "total_candidates": debug_result.total_candidates,
        "total_passed_threshold": sum(1 for c in debug_result.chunks if c.passed_threshold),
        "dense_search_ms": debug_result.dense_search_ms,
        "bm25_search_ms": debug_result.bm25_search_ms,
        "total_search_ms": debug_result.total_search_ms,
        "formatted_context": formatted_context,
        "context_char_count": len(formatted_context),
        "estimated_context_tokens": len(formatted_context) // 4
    }
```

---

## Phase 4: API ì—”ë“œí¬ì¸íŠ¸

### íŒŒì¼: `agent-server/agent_server/routers/rag.py`

```python
@router.post("/debug", response_model=DebugSearchResponse)
async def debug_search(request: DebugSearchRequest) -> DebugSearchResponse:
    """
    RAG ê²€ìƒ‰ ë””ë²„ê¹… - ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¦¬ë‹ˆì§€ ì¶”ì 

    ì‚¬ìš© ì‚¬ë¡€:
    - íŠ¹ì • ì²­í¬ê°€ ì™œ ê²€ìƒ‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
    - ì ìˆ˜ ê³„ì‚°ì´ ìµœì¢… RAG ì»¨í…ìŠ¤íŠ¸ì— ì–´ë–»ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ë¶„ì„

    ë°˜í™˜ ì •ë³´:
    - ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°ì§€ ê²°ê³¼
    - ì²­í¬ë³„ Dense/BM25/Fused ì ìˆ˜
    - ìµœì¢… í¬ë§·ëœ ì»¨í…ìŠ¤íŠ¸
    """
    rag_manager = get_rag_manager()

    if not rag_manager.is_ready:
        raise HTTPException(status_code=503, detail="RAG system not ready")

    result = await rag_manager.debug_search(
        query=request.query,
        imported_libraries=request.imported_libraries,
        top_k=request.top_k,
        include_full_content=request.include_full_content,
        simulate_plan_context=request.simulate_plan_context
    )

    return DebugSearchResponse(**result)
```

---

## Phase 5: CLI ìŠ¤í¬ë¦½íŠ¸

### íŒŒì¼: `agent-server/scripts/debug_rag.py` (ì‹ ê·œ ìƒì„±)

```bash
# ì‚¬ìš© ì˜ˆì‹œ
python -m scripts.debug_rag "pandasë¡œ ë°ì´í„°í”„ë ˆìž„ ë§Œë“¤ì–´ì¤˜"
python -m scripts.debug_rag "ì‹œê°í™” ì½”ë“œ" --libs matplotlib seaborn
python -m scripts.debug_rag "test query" --top-k 10 --verbose
python -m scripts.debug_rag "test query" --json  # JSON ì¶œë ¥
```

ì¶œë ¥ í¬ë§·:
```
================================================================================
 RAG DEBUG RESULTS
================================================================================

Query: pandasë¡œ ë°ì´í„°í”„ë ˆìž„ ë§Œë“¤ì–´ì¤˜
Imported Libraries: (none)
Detected Libraries: ['pandas']

================================================================================
 SEARCH CONFIGURATION
================================================================================
  top_k: 5
  score_threshold: 0.3
  use_hybrid_search: True
  hybrid_alpha: 0.5

================================================================================
 TIMING
================================================================================
  Dense search: 12.34 ms
  BM25 search: 3.21 ms
  Total: 18.76 ms

================================================================================
 RETRIEVED CHUNKS
================================================================================
Total candidates: 15
Passed threshold: 5

 Rank   Dense    BM25    Fused   Pass   Source
--------------------------------------------------------------------------------
  1    0.9234  0.8123  0.8679   YES   pandas.md > DataFrame Creation
  2    0.8567  0.7890  0.8229   YES   pandas.md > Data Loading
  3    0.7234  0.6543  0.6889   YES   numpy.md > Array Operations
  ...

================================================================================
 FORMATTED CONTEXT
================================================================================
Character count: 2456
Estimated tokens: 614

## ðŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ API ì°¸ì¡° (RAG Retrieved)

ì•„ëž˜ ê°€ì´ë“œì˜ API ì‚¬ìš©ë²•ì„ **ë°˜ë“œì‹œ** ë”°ë¥´ì„¸ìš”.

[Source: pandas.md > DataFrame Creation (relevance: 0.87)]
...
```

---

## Phase 6: ìœ ë‹›í…ŒìŠ¤íŠ¸

### íŒŒì¼: `agent-server/tests/test_rag_components.py`

ì¶”ê°€í•  í…ŒìŠ¤íŠ¸ í´ëž˜ìŠ¤:

```python
class TestRAGDebug:
    """Retriever.search_with_debug() í…ŒìŠ¤íŠ¸"""

    def test_search_with_debug_returns_all_scores(self):
        """search_with_debugëŠ” dense, bm25, fused ì ìˆ˜ë¥¼ ëª¨ë‘ ë°˜í™˜í•´ì•¼ í•¨"""

    def test_search_with_debug_dense_scores_descending(self):
        """fused ì ìˆ˜ëŠ” ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ì•¼ í•¨"""

    def test_search_with_debug_threshold_filtering(self):
        """passed_thresholdê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ì•¼ í•¨"""

    def test_debug_search_timing_present(self):
        """íƒ€ì´ë° ì •ë³´ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨"""


class TestRAGManagerDebug:
    """RAGManager.debug_search() í…ŒìŠ¤íŠ¸"""

    def test_debug_search_returns_library_detection(self):
        """debug_searchëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°ì§€ ì •ë³´ë¥¼ ë°˜í™˜í•´ì•¼ í•¨"""

    def test_debug_search_not_ready_returns_error(self):
        """RAGê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ì„ ë•Œ ì—ëŸ¬ ë°˜í™˜"""


class TestDebugSchemas:
    """ë””ë²„ê·¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸"""

    def test_debug_search_request_validation(self):
        """DebugSearchRequest ê²€ì¦"""

    def test_debug_search_request_defaults(self):
        """ê¸°ë³¸ê°’ í™•ì¸"""

    def test_chunk_debug_info_validation(self):
        """ChunkDebugInfo ê²€ì¦"""
```

---

## ìˆ˜ì • íŒŒì¼ ëª©ë¡

| íŒŒì¼ | ìž‘ì—… |
|------|------|
| `agent-server/agent_server/schemas/rag.py` | ë””ë²„ê·¸ ìŠ¤í‚¤ë§ˆ ì¶”ê°€ |
| `agent-server/agent_server/core/retriever.py` | `search_with_debug()` ë©”ì„œë“œ ì¶”ê°€ |
| `agent-server/agent_server/core/rag_manager.py` | `debug_search()` ë©”ì„œë“œ ì¶”ê°€ |
| `agent-server/agent_server/routers/rag.py` | `POST /rag/debug` ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ |
| `agent-server/scripts/debug_rag.py` | CLI ìŠ¤í¬ë¦½íŠ¸ ì‹ ê·œ ìƒì„± |
| `agent-server/tests/test_rag_components.py` | ë””ë²„ê·¸ í…ŒìŠ¤íŠ¸ ì¶”ê°€ |

---

## êµ¬í˜„ ìˆœì„œ

1. **schemas/rag.py** - ë°ì´í„° êµ¬ì¡° ë¨¼ì € ì •ì˜
2. **core/retriever.py** - í•µì‹¬ ë””ë²„ê·¸ ê²€ìƒ‰ ë¡œì§
3. **core/rag_manager.py** - ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´
4. **routers/rag.py** - API ë…¸ì¶œ
5. **scripts/debug_rag.py** - CLI ë„êµ¬
6. **tests/test_rag_components.py** - í…ŒìŠ¤íŠ¸ ì¶”ê°€
7. ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²€ì¦

---

## ì˜ˆìƒ ê²°ê³¼

### CLI ì‚¬ìš© ì˜ˆì‹œ
```bash
$ python -m scripts.debug_rag "daskë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬í•˜ëŠ” ì½”ë“œ ìž‘ì„±í•´ì¤˜" --verbose

Query: daskë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬í•˜ëŠ” ì½”ë“œ ìž‘ì„±í•´ì¤˜
Detected Libraries: ['dask']

 Rank   Dense    BM25    Fused   Pass   Source
--------------------------------------------------------------------------------
  1    0.9456  0.8912  0.9184   YES   dask.md > DataFrame Operations
  2    0.8823  0.7654  0.8239   YES   dask.md > Parallel Computing
  3    0.7234  0.6123  0.6679   YES   pandas.md > Large Data Handling
```

### API ì‚¬ìš© ì˜ˆì‹œ
```bash
$ curl -X POST http://localhost:8765/rag/debug \
  -H "Content-Type: application/json" \
  -d '{"query": "pandas dataframe", "imported_libraries": ["pandas"]}'
```
